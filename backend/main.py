from fastapi import FastAPI, HTTPException, Query
from fastapi.middleware.cors import CORSMiddleware
import uvicorn
import os
from datetime import datetime
from typing import List, Optional
from crawler import NaverStockNewsCrawler, NaverNewsSearchCrawler

# FastAPI ì•± ìƒì„±
app = FastAPI(
    title="kjgmacro Stock Alert API",
    description="ì‹¤ì‹œê°„ ì£¼ì‹ ë‰´ìŠ¤ ì•Œë¦¼ ì„œë²„ - kjgmacro.com",
    version="1.0.0",
    docs_url="/docs",  # API ë¬¸ì„œ ê²½ë¡œ
    redoc_url="/redoc"  # ëŒ€ì²´ ë¬¸ì„œ ê²½ë¡œ
)

# CORS ì„¤ì • (ëª¨ë°”ì¼ ì•±ì—ì„œ ì ‘ê·¼ ê°€ëŠ¥í•˜ë„ë¡)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ê°œë°œ ë‹¨ê³„ì—ì„œëŠ” ëª¨ë“  ë„ë©”ì¸ í—ˆìš©
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# í¬ë¡¤ëŸ¬ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
news_crawler = NaverStockNewsCrawler()
search_crawler = NaverNewsSearchCrawler()

# ê¸°ë³¸ ê´€ì‹¬ ì¢…ëª© (ë‚˜ì¤‘ì— DBë‚˜ ì‚¬ìš©ì ì„¤ì •ìœ¼ë¡œ ë³€ê²½)
DEFAULT_WATCHLIST = [
    {"code": "005930", "name": "ì‚¼ì„±ì „ì"},
    {"code": "000660", "name": "SKí•˜ì´ë‹‰ìŠ¤"},
    {"code": "035720", "name": "ì¹´ì¹´ì˜¤"},
    {"code": "051910", "name": "LGí™”í•™"},
    {"code": "006400", "name": "ì‚¼ì„±SDI"}
]

@app.get("/")
def root():
    """ì„œë²„ ìƒíƒœ ë° ê¸°ë³¸ ì •ë³´"""
    return {
        "service": "kjgmacro Stock Alert Server",
        "status": "running",
        "version": "1.0.0",
        "description": "ì‹¤ì‹œê°„ ì£¼ì‹ ë‰´ìŠ¤ í¬ë¡¤ë§ ë° ì•Œë¦¼ ì„œë¹„ìŠ¤",
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "endpoints": {
            "health": "/api/health",
            "news": "/api/news/{stock_code}",
            "alerts": "/api/alerts",
            "watchlist": "/api/watchlist",
            "docs": "/docs"
        }
    }

@app.get("/api/health")
def health_check():
    """í—¬ìŠ¤ ì²´í¬ (Google Cloud Runì—ì„œ ì‚¬ìš©)"""
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "uptime": "ì„œë²„ ì •ìƒ ì‘ë™ ì¤‘"
    }

@app.get("/api/news/{stock_code}")
def get_stock_news(
    stock_code: str,
    limit: int = Query(default=10, ge=1, le=50, description="ê°€ì ¸ì˜¬ ë‰´ìŠ¤ ê°œìˆ˜")
):
    """ì¢…ëª©ì½”ë“œë¥¼ ì¢…ëª©ëª…ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ë‰´ìŠ¤ ê²€ìƒ‰"""
    
    # ì¢…ëª©ì½”ë“œ â†’ ì¢…ëª©ëª… ë§¤í•‘
    code_to_name = {
        "005930": "ì‚¼ì„±ì „ì",
        "000660": "SKí•˜ì´ë‹‰ìŠ¤", 
        "035720": "ì¹´ì¹´ì˜¤",
        "051910": "LGí™”í•™",
        "006400": "ì‚¼ì„±SDI"
    }
    
    keyword = code_to_name.get(stock_code, stock_code)
    
    try:
        print(f"[API ìš”ì²­] {stock_code} â†’ '{keyword}' ë‰´ìŠ¤ {limit}ê°œ ê²€ìƒ‰")
        
        # ìƒˆë¡œìš´ ê²€ìƒ‰ í¬ë¡¤ëŸ¬ ì‚¬ìš©
        news_list = search_crawler.get_news_by_keyword(keyword, limit)
        
        if not news_list:
            return {
                "success": False,
                "message": f"'{keyword}' ê´€ë ¨ ë‰´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                "stock_code": stock_code,
                "keyword": keyword,
                "count": 0,
                "data": []
            }
        
        return {
            "success": True,
            "stock_code": stock_code,
            "keyword": keyword,
            "count": len(news_list),
            "data": news_list,
            "crawled_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }
        
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"ë‰´ìŠ¤ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {str(e)}"
        )

@app.get("/api/alerts")
def get_alerts(priority: Optional[str] = None, limit: int = 20):
    """
    ì¢…í•© ì•Œë¦¼ ëª©ë¡ ì¡°íšŒ (ê´€ì‹¬ ì¢…ëª©ë“¤ì˜ ë‰´ìŠ¤ ìš”ì•½)
    
    - **priority**: ìš°ì„ ìˆœìœ„ í•„í„° (high/medium/low)
    - **limit**: ìµœëŒ€ ì•Œë¦¼ ê°œìˆ˜
    """
    try:
        alerts = []
        
        # ê´€ì‹¬ ì¢…ëª©ë“¤ì˜ ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘
        for stock in DEFAULT_WATCHLIST[:5]:  # ì²˜ìŒ 5ê°œë§Œ (í…ŒìŠ¤íŠ¸ìš©)
            stock_code = stock["code"]
            stock_name = stock["name"]
            
            # ê° ì¢…ëª©ë‹¹ ìµœëŒ€ 3ê°œ ë‰´ìŠ¤
            news_list = news_crawler.get_stock_news(stock_code, 3)
            
            if news_list:
                # ì•Œë¦¼ ë°ì´í„° ìƒì„±
                alert = {
                    "id": f"alert_{stock_code}_{int(datetime.now().timestamp())}",
                    "stock_code": stock_code,
                    "stock_name": stock_name,
                    "title": f"{stock_name} ê´€ë ¨ ë‰´ìŠ¤ {len(news_list)}ê±´ ì—…ë°ì´íŠ¸",
                    "summary": f"ìµœê·¼ {stock_name} ê´€ë ¨í•˜ì—¬ {len(news_list)}ê±´ì˜ ë‰´ìŠ¤ê°€ í™•ì¸ë˜ì—ˆìŠµë‹ˆë‹¤.",
                    "article_count": len(news_list),
                    "priority": "high" if len(news_list) >= 3 else "medium",
                    "created_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    "latest_news": news_list[:2],  # ìµœì‹  2ê°œë§Œ ë¯¸ë¦¬ë³´ê¸°
                    "sentiment": "neutral"  # ë‚˜ì¤‘ì— ê°ì„±ë¶„ì„ ì¶”ê°€ ì˜ˆì •
                }
                alerts.append(alert)
        
        # ìš°ì„ ìˆœìœ„ í•„í„°ë§
        if priority:
            alerts = [a for a in alerts if a["priority"] == priority]
        
        return {
            "success": True,
            "count": len(alerts),
            "alerts": alerts[:limit],
            "generated_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }
        
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"ì•Œë¦¼ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )

@app.get("/api/watchlist")
def get_watchlist():
    """ê´€ì‹¬ ì¢…ëª© ëª©ë¡ ì¡°íšŒ"""
    return {
        "success": True,
        "watchlist": DEFAULT_WATCHLIST,
        "count": len(DEFAULT_WATCHLIST)
    }

@app.get("/api/multiple-news")
def get_multiple_news(
    codes: str = Query(..., description="ì¢…ëª©ì½”ë“œë“¤ (ì‰¼í‘œë¡œ êµ¬ë¶„, ì˜ˆ: 005930,000660)"),
    limit_each: int = Query(default=5, description="ì¢…ëª©ë‹¹ ë‰´ìŠ¤ ê°œìˆ˜")
):
    """
    ì—¬ëŸ¬ ì¢…ëª©ì˜ ë‰´ìŠ¤ë¥¼ í•œ ë²ˆì— ì¡°íšŒ
    
    - **codes**: ì¢…ëª©ì½”ë“œë“¤ì„ ì‰¼í‘œë¡œ êµ¬ë¶„ (ì˜ˆ: 005930,000660,035720)
    - **limit_each**: ì¢…ëª©ë‹¹ ê°€ì ¸ì˜¬ ë‰´ìŠ¤ ê°œìˆ˜
    """
    try:
        stock_codes = [code.strip() for code in codes.split(",")]
        
        if len(stock_codes) > 10:
            raise HTTPException(
                status_code=400,
                detail="í•œ ë²ˆì— ìµœëŒ€ 10ê°œ ì¢…ëª©ê¹Œì§€ë§Œ ì¡°íšŒ ê°€ëŠ¥í•©ë‹ˆë‹¤."
            )
        
        # ì—¬ëŸ¬ ì¢…ëª© ë‰´ìŠ¤ ìˆ˜ì§‘
        results = news_crawler.get_multiple_stocks_news(stock_codes, limit_each)
        
        return {
            "success": True,
            "requested_codes": stock_codes,
            "results": results,
            "crawled_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }
        
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"ë‹¤ì¤‘ ë‰´ìŠ¤ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {str(e)}"
        )

# ì„œë²„ ì‹¤í–‰ ì„¤ì •
if __name__ == "__main__":
    # Google Cloud Runì€ PORT í™˜ê²½ë³€ìˆ˜ë¥¼ ì‚¬ìš©
    port = int(os.environ.get("PORT", 8080))
    
    print(f"""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘           kjgmacro ì£¼ì‹ ì•Œë¦¼ ì„œë²„            â•‘
    â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
    â•‘  ğŸŒ ì„œë²„ ì£¼ì†Œ: http://localhost:{port}        â•‘
    â•‘  ğŸ“š API ë¬¸ì„œ: http://localhost:{port}/docs    â•‘
    â•‘  âš¡ ìƒíƒœ: ì‹¤ì‹œê°„ ë‰´ìŠ¤ í¬ë¡¤ë§ ì¤€ë¹„ ì™„ë£Œ      â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=port,
        reload=True,  # ì½”ë“œ ë³€ê²½ ì‹œ ìë™ ì¬ì‹œì‘
        log_level="info"
    )
